import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import time
import requests
import langdetect
from deep_translator import GoogleTranslator
import os

# ======= Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª =======
model_cat_path = "models/model_cat"
model_cat0_path = "models/model_cat0"

label_map1 = {
    0: "DESCRIPTION", 1: "ENTITY", 2: "ABBREVIATION", 3: "HUMAN",
    4: "NUMERIC", 5: "LOCATION"
}

label_map2 = {
    0: "manner", 1: "cremat", 2: "animal", 3: "exp", 4: "ind", 5: "gr", 6: "title",
    7: "def", 8: "date", 9: "reason", 10: "event", 11: "state", 12: "desc", 13: "count",
    14: "other", 15: "letter", 16: "religion", 17: "food", 18: "country", 19: "color",
    20: "termeq", 21: "city", 22: "body", 23: "dismed", 24: "mount", 25: "money",
    26: "product", 27: "period", 28: "substance", 29: "sport", 30: "plant", 31: "techmeth",
    32: "volsize", 33: "instru", 34: "abb", 35: "speed", 36: "word", 37: "lang",
    38: "perc", 39: "code", 40: "dist", 41: "temp", 42: "symbol", 43: "ord",
    44: "veh", 45: "weight", 46: "currency"
}

label_map1_ar = {
    0: "ÙˆØµÙ", 1: "ÙƒÙŠØ§Ù†", 2: "Ø§Ø®ØªØµØ§Ø±", 3: "Ø´Ø®Øµ",
    4: "Ø±Ù‚Ù…ÙŠ", 5: "Ù…ÙƒØ§Ù†"
}

label_map2_ar = {
    0: "Ø·Ø±ÙŠÙ‚Ø©", 1: "Ù…ÙˆØª", 2: "Ø­ÙŠÙˆØ§Ù†", 3: "ØªØ¬Ø±Ø¨Ø©", 4: "ÙØ±Ø¯", 5: "Ø´Ø¬Ø±Ø©",
    6: "Ø¹Ù†ÙˆØ§Ù†", 7: "ØªØ¹Ø±ÙŠÙ", 8: "ØªØ§Ø±ÙŠØ®", 9: "Ø³Ø¨Ø¨", 10: "Ø­Ø¯Ø«", 11: "Ø­Ø§Ù„Ø©",
    12: "ÙˆØµÙ", 13: "Ø¹Ø¯Ø¯", 14: "Ø£Ø®Ø±Ù‰", 15: "Ø­Ø±Ù", 16: "Ø¯ÙŠÙ†", 17: "Ø·Ø¹Ø§Ù…",
    18: "Ø¯ÙˆÙ„Ø©", 19: "Ù„ÙˆÙ†", 20: "Ù…ØµØ·Ù„Ø­", 21: "Ù…Ø¯ÙŠÙ†Ø©", 22: "Ø¬Ø³Ù…", 23: "Ù…Ø±Ø¶",
    24: "Ø¬Ø¨Ù„", 25: "Ù…Ø§Ù„", 26: "Ù…Ù†ØªØ¬", 27: "ÙØªØ±Ø©", 28: "Ù…Ø§Ø¯Ø©", 29: "Ø±ÙŠØ§Ø¶Ø©",
    30: "Ù†Ø¨Ø§Øª", 31: "Ø·Ø±ÙŠÙ‚Ø© ØªÙ‚Ù†ÙŠØ©", 32: "Ø­Ø¬Ù…", 33: "Ø£Ø¯Ø§Ø©", 34: "Ø§Ø®ØªØµØ§Ø±",
    35: "Ø³Ø±Ø¹Ø©", 36: "ÙƒÙ„Ù…Ø©", 37: "Ù„ØºØ©", 38: "Ù†Ø³Ø¨Ø©", 39: "ÙƒÙˆØ¯", 40: "Ù…Ø³Ø§ÙØ©",
    41: "Ø¯Ø±Ø¬Ø© Ø­Ø±Ø§Ø±Ø©", 42: "Ø±Ù…Ø²", 43: "ØªØ±ØªÙŠØ¨", 44: "Ù…Ø±ÙƒØ¨Ø©", 45: "ÙˆØ²Ù†", 46: "Ø¹Ù…Ù„Ø©"
}

@st.cache_resource
def load_models():
    tokenizer_cat = AutoTokenizer.from_pretrained(model_cat_path)
    model_cat = AutoModelForSequenceClassification.from_pretrained(model_cat_path)
    tokenizer_cat0 = AutoTokenizer.from_pretrained(model_cat0_path)
    model_cat0 = AutoModelForSequenceClassification.from_pretrained(model_cat0_path)
    return tokenizer_cat, model_cat, tokenizer_cat0, model_cat0

tokenizer_cat, model_cat, tokenizer_cat0, model_cat0 = load_models()

# ======= Ø¥Ø¹Ø¯Ø§Ø¯ Ollama =======
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "phi"

def translate_to_english(text):
    return GoogleTranslator(source='auto', target='en').translate(text)

def query_ollama(question, cat1, cat2, original_question, lang):
    # Ø±Ø¯ Ø®Ø§Øµ Ù„Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ù‚ØµÙŠØ¯Ø© ØµÙˆØª ØµÙÙŠØ± Ø§Ù„Ø¨Ù„Ø¨Ù„
    ssb ="""ØµÙˆØª ØµÙÙŠØ± Ø§Ù„Ø¨Ù„Ø¨Ù„\n
--------------\n
Ø§Ù„Ø§ØµÙ…Ø¹ÙŠ\n
--------------\n
ØµÙÙ€Ù€ÙˆÙ’ØªÙ ØµÙÙ€ÙÙ€ÙŠØ±Ù Ø§Ù„Ù€Ø¨ÙÙ€Ù„Ù’Ø¨ÙÙ„Ù Ù‡ÙÙ€ÙŠÙ‘ÙÙ€Ø¬Ù Ù‚ÙÙ€Ù„Ù’Ù€Ø¨ÙÙŠÙ Ø§Ù„Ù€Ø«ÙÙ€Ù…ÙÙ„Ù\n
Ø§Ù„Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù…ÙÙ€Ù€Ù€Ù€Ù€Ù€Ù€Ø§Ø¡Ù ÙˆÙØ§Ù„Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ø²Ù‘ÙÙ‡Ù’Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ø±Ù Ù…ÙÙ€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ø¹ÙÙ€Ù€Ù€Ù€Ù€Ù€Ù€Ø§Ù‹\n
Ù…ÙÙ€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ø¹Ù Ø²ÙÙ‡Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ø±Ù Ù„ÙÙ€Ù€Ù€Ù€Ù€Ø­Ù’Ù€Ù€Ù€Ù€Ø¸Ù Ø§Ù„Ù€Ù€Ù€Ù…ÙÙ€Ù€Ù€Ù‚ÙÙ€Ù€Ù€Ù„Ù\n
ÙˆÙØ£ÙÙ†Ù’Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€ØªÙ ÙŠÙÙ€Ù€Ù€Ù€Ù€Ø§Ø³ÙÙ€Ù€Ù€Ù€Ù€ÙŠÙ‘ÙÙ€Ù€Ù€Ù€Ù€Ø¯Ù Ù„ÙÙ€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€ÙŠ\n
ÙˆÙØ³ÙÙ€Ù€Ù€Ù€Ù€Ù€Ù€ÙŠÙ‘ÙÙ€Ù€Ù€Ù€Ù€Ù€Ù€Ø¯ÙÙŠ ÙˆÙÙ…ÙÙ€Ù€Ù€Ù€Ù€Ù€Ù€ÙˆÙ’Ù„ÙÙ€Ù€Ù€Ù€Ù€Ù€Ù€Ù‰ Ù„ÙÙ€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€ÙŠ\n
ÙÙÙ€Ù€Ù€ÙƒÙÙ€Ù€Ù…Ù’ ÙÙÙ€Ù€Ù€ÙƒÙÙ€Ù€Ù…Ù’ ØªÙÙ€Ù€ÙŠÙ‘ÙÙ€Ù…ÙÙ€Ù†ÙÙ€ÙŠ ØºÙÙ€Ù€Ù€Ø²ÙÙŠÙ‘ÙÙ€Ù€Ù„ÙŒ Ø¹ÙÙ€Ù‚ÙÙ€ÙŠÙ’Ù€Ù‚ÙÙ€Ù„Ù€ÙŠ\n
Ù‚ÙÙ€Ø·Ù‘ÙÙ€ÙÙ’Ù€ØªÙ Ù…ÙÙ€Ù€Ù†Ù’ ÙˆÙØ¬Ù’Ù€Ù†ÙÙ€ØªÙÙ‡Ù Ù…ÙÙ€Ù€Ù†Ù’ Ù„ÙÙ€Ø«Ù’Ù€Ù…Ù ÙˆÙØ±Ù’Ø¯Ù Ø§Ù„Ù€Ø®ÙÙ€Ø¬ÙÙ„Ù\n
ÙÙÙ€Ù€Ù‚ÙÙ€Ø§Ù„Ù Ù„Ø§Ù Ù„Ø§Ù Ù„Ø§Ù Ù„Ø§Ù Ù„Ø§Ù Ù„Ø§Ù ÙˆÙÙ‚ÙÙ€Ù€Ù€Ø¯Ù’ ØºÙÙ€Ù€Ù€Ø¯ÙØ§ Ù…ÙÙ€Ù‡ÙÙ€Ø±Ù’ÙˆÙÙ„Ù\n
ÙˆØ§Ù„Ù€Ø®ÙÙ€ÙˆØ¯Ù Ù…ÙÙ€Ø§Ù„ÙÙ€ØªÙ’ Ø·ÙÙ€Ø±ÙØ¨ÙÙ€Ø§Ù‹ Ù…ÙÙ€Ù€Ù†Ù’ ÙÙÙ€Ø¹Ù’Ù„Ù Ù‡ÙÙ€Ø°ÙØ§ Ø§Ù„Ù€Ø±Ù‘ÙØ¬ÙÙ„Ù\n
ÙÙÙ€ÙˆÙÙ„Ù’Ù€ÙˆÙÙ„ÙÙ€ØªÙ’ ÙˆÙÙˆÙÙ„Ù’Ù€Ù€ÙˆÙÙ„ÙÙ€ØªÙ ÙˆÙÙ„Ù€Ù€Ù€ÙŠ ÙˆÙÙ„Ù€Ù€Ù€ÙŠ ÙŠÙÙ€Ù€Ø§ÙˆÙÙŠÙ’Ù€Ù„Ù Ù„ÙÙ€Ù€ÙŠ\n
Ù‚ÙÙ€Ù€Ø§Ù„ÙÙ€ØªÙ’ Ù„ÙÙ€Ù€Ù€Ù‡Ù Ø­ÙÙ€ÙŠÙ’Ù€Ù†Ù ÙƒÙÙ€Ù€Ø°ÙØ§ Ø§Ù†Ù’Ù€Ù‡ÙÙ€Ø¶Ù’ ÙˆÙØ¬ÙÙ€Ù€Ø¯Ù’ Ø¨ÙÙ€Ø§Ù„Ù€Ù†Ù‘ÙÙ‚ÙÙ„Ù\n
ÙˆÙÙÙÙ€Ù€ØªÙ’Ù€Ù€ÙŠÙÙ€Ø©Ù Ø³ÙÙ€Ù‚ÙÙ€ÙˆÙ’Ù†ÙÙ€Ù†ÙÙ€ÙŠ Ù‚ÙÙ€Ù€Ù‡Ù’Ù€Ù€ÙˆÙØ©Ù‹ ÙƒÙÙ€Ø§Ù„Ù€Ø¹ÙÙ€Ø³ÙÙ€Ù„Ù Ù„ÙÙ€Ù€Ù€Ù€ÙŠ\n
Ø´ÙÙ€Ù…ÙÙ€Ù…Ù’Ù€ØªÙÙ€Ù‡ÙØ§ Ø¨ÙÙ€Ù€Ø£ÙÙ†Ù’Ù€ÙÙÙ€ÙŠ Ø£ÙØ²Ù’ÙƒÙÙ€Ù€Ù€Ù€Ù‰ Ù…ÙÙ€Ù€Ù€Ù€Ù†Ù Ø§Ù„Ù€Ù‚ÙÙ€Ø±ÙÙ†Ù’Ù€ÙÙÙ„Ù\n
ÙÙÙ€Ù€ÙŠ ÙˆÙØ³Ù’Ù€Ù€Ø·Ù Ø¨ÙÙ€Ø³Ù’Ù€ØªÙØ§Ù†Ù Ø­ÙÙ€Ù„ÙÙŠ Ø¨Ù€Ø§Ù„Ø²Ù‘ÙÙ‡Ù’Ø±Ù ÙˆÙØ§Ù„Ù€Ø³ÙØ±ÙÙˆØ±Ù Ù„ÙÙ€ÙŠ\n
ÙˆÙØ§Ù„Ù€Ø¹ÙÙ€ÙˆØ¯Ù Ø¯ÙÙ†Ù’ Ø¯ÙÙ†Ù’Ù€Ù€Ø¯ÙÙ†Ù Ù„ÙÙ€ÙŠ ÙˆÙØ§Ù„Ù€Ø·Ù‘ÙØ¨Ù’Ù„Ù Ø·ÙÙ€Ø¨Ù’ Ø·ÙÙ€Ø¨Ù‘ÙÙ„Ù Ù„ÙÙ€ÙŠ\n
Ø·ÙÙ€Ù€Ø¨ Ø·ÙÙ€Ù€Ø¨Ù Ø·ÙÙ€Ø¨ Ø·ÙÙ€Ø¨Ù Ø·ÙÙ€Ø¨ Ø·ÙÙ€Ø¨ Ø·ÙÙ€Ø¨Ù Ù„Ù€ÙŠ\n
ÙˆÙØ§Ù„Ø³Ù‘ÙÙ‚Ù’ÙÙ Ù‚ÙØ¯Ù’ Ø³ÙÙ‚Ù’Ø³ÙÙ‚Ù Ù„ÙÙŠ ÙˆÙØ§Ù„Ø±Ù‘ÙÙ‚Ù’ØµÙ Ù‚ÙØ¯Ù’ Ø·ÙØ§Ø¨Ù Ø¥Ù„ÙÙŠ\n
Ø´ÙÙ€Ù€Ù€ÙˆÙÙ‰ Ø´ÙÙ€Ù€Ù€ÙˆÙÙ‰ ÙˆÙØ´ÙÙ€Ø§Ù‡ÙÙ€Ø´Ù Ø¹ÙÙ€Ù„ÙÙ€Ù‰ ÙˆÙØ±ÙÙ‚Ù’ Ø³ÙÙ€ÙÙÙ€Ø±Ø¬ÙÙ„Ù\n
ÙˆÙØºÙÙ€Ù€Ù€Ø±Ù‘ÙØ¯Ù Ø§Ù„Ù€Ù‚ÙÙ€Ù…Ù’Ù€Ø±Ù ÙŠÙÙ€ØµÙÙ€ÙŠÙ€Ø­Ù Ù…ÙÙ€Ù€Ù€Ù†Ù’ Ù…ÙÙ€Ù„ÙÙ€Ù„Ù ÙÙÙ€Ù€ÙŠ Ù…ÙÙ€Ù„ÙÙ€Ù„Ù\n
ÙÙÙ€Ù€Ù€Ù„ÙÙ€Ù€ÙˆÙ’ ØªÙÙ€Ù€Ø±ÙØ§Ù†ÙÙ€Ù€ÙŠ Ø±ÙØ§ÙƒÙÙ€Ù€Ø¨Ù€Ù€Ø§Ù‹ Ø¹ÙÙ€Ù€Ù„ÙÙ€Ù€Ù‰ Ø­ÙÙ€Ù€Ù…ÙÙ€Ù€Ø§Ø±Ù Ø£ÙÙ‡Ù’Ù€Ù€Ù€Ù€Ø²ÙÙ„Ù\n
ÙŠÙÙ€Ù€Ù…Ù’Ù€Ø´ÙÙ€ÙŠ Ø¹ÙÙ€Ù€Ù„ÙÙ€Ù€Ù‰ Ø«ÙÙ€Ù€Ù„Ø§Ø«ÙÙ€Ù€Ø©Ù ÙƒÙÙ€Ù…ÙÙ€Ø´Ù’Ù€ÙŠÙØ©Ù Ø§Ù„Ù€Ø¹ÙÙ€Ø±ÙÙ†Ù’Ù€Ø¬ÙÙ„Ù\n
ÙˆÙØ§Ù„Ù€Ù†Ù‘ÙÙ€Ø§Ø³Ù ØªÙÙ€Ø±Ù’Ø¬ÙÙ€Ù…Ù’ Ø¬ÙÙ€Ù…ÙÙ€Ù„ÙÙŠ ÙÙÙ€Ù€ÙŠ Ø§Ù„Ù€Ø³ÙÙ€ÙˆÙ‚Ù Ø¨Ù€Ø§Ù„Ù‚ÙÙ„Ù’Ù‚ÙÙ„ÙÙ„Ù\n
ÙˆÙØ§Ù„Ù€Ù€ÙƒÙÙ€Ù„Ù‘Ù ÙƒÙÙ€Ø¹Ù’Ù€ÙƒÙÙ€Ø¹Ù’ ÙƒÙÙ€Ø¹ÙÙ€ÙƒÙØ¹Ù’ Ø®ÙÙ€Ù„Ù’Ù€ÙÙÙŠ ÙˆÙÙ…ÙÙ€Ù€Ù†Ù’ Ø­ÙÙ€ÙˆÙÙŠÙ’Ù€Ù„ÙÙ„ÙÙŠ\n
Ù„Ù€ÙƒÙÙ€Ù†Ù’ Ù…ÙÙ€Ø´ÙÙ€ÙŠØªÙ Ù‡ÙÙ€Ø§Ø±ÙØ¨Ù€Ø§ Ù…ÙÙ€Ù€Ù†Ù’ Ø®ÙÙ€Ø´Ù’Ù€ÙŠÙØ©Ù Ø§Ù„Ù€Ø¹ÙÙ€Ù‚ÙÙ†Ù’Ù‚ÙÙ„ÙÙŠ\n
Ø¥ÙÙ„ÙÙ€Ù€Ù€Ù€Ù€Ù€Ù‰ Ù„ÙÙ€Ù€Ù€Ù‚ÙÙ€Ù€Ù€Ø§Ø¡Ù Ù…ÙÙ€Ù€Ù€Ù„ÙÙ€Ù€Ù€ÙƒÙ Ù…ÙÙ€Ù€Ø¹ÙÙ€Ù€Ø¸Ù‘ÙÙ€Ù€Ù…Ù Ù…ÙÙ€Ù€Ø¨ÙÙ€Ù€Ø¬Ù‘ÙÙ€Ù€Ù„Ù\n
ÙŠÙÙ€Ù€Ø£Ù’Ù…ÙÙ€Ù€Ø±ÙÙ„ÙÙ€ÙŠ Ø¨ÙÙ€Ù€Ø®ÙÙ€Ù„Ù’Ù€Ø¹ÙÙ€Ø©Ù Ø­ÙÙ€Ù€Ù…Ù’Ù€Ù€Ø±ÙØ§Ø¡Ù ÙƒÙÙ€Ù€Ø§Ù„Ù€Ù€Ø¯Ù‘ÙÙ…Ù’ Ø¯ÙÙ…ÙÙ€Ù€Ù„ÙÙ€Ù€ÙŠ\n
Ø£ÙØ¬ÙÙ€Ù€Ù€Ù€Ù€Ù€Ø±Ù‘Ù ÙÙÙ€Ù€ÙŠÙ€Ù€Ù‡ÙÙ€Ø§ Ù…ÙÙ€Ù€Ø§Ø´ÙÙ€Ù€ÙŠÙ€Ø§Ù‹ Ù…ÙÙ€Ù€Ø¨ÙÙ€Ù€ØºÙ’Ù€Ø¯ÙØ¯ÙØ§Ù‹ Ù„Ù€Ù€Ù„Ù€Ù€Ø°ÙŠÙ‘ÙÙ€Ù„Ù\n
Ø£ÙÙ†ÙÙ€Ù€Ø§ Ø§Ù„Ø£ÙØ¯ÙÙŠÙ’Ù€Ø¨Ù Ø§Ù„Ø£ÙÙ„Ù’Ù€Ù…ÙØ¹ÙÙŠ Ù…ÙÙ€Ù†Ù’ Ø­ÙÙ€ÙŠÙ‘Ù Ø£ÙØ±Ù’Ø¶Ù Ø§Ù„Ù€Ù…ÙÙˆÙ’ØµÙÙ„Ù\n
Ù†ÙÙ€Ø¸ÙÙ€Ù…Ù’ØªÙ Ù‚ÙÙ€Ø·ÙÙ€Ø¹Ø§Ù‹ Ø²ÙØ®Ù’Ù€Ø±ÙÙÙØªÙ’ ÙŠÙÙ€Ø¹Ù’Ø¬ÙØ²Ù Ø¹ÙÙ€Ù†Ù’Ù‡ÙØ§ Ø§Ù„Ø£ÙØ¯Ù’Ø¨Ù Ù„ÙÙ€ÙŠ\n
Ø£ÙÙ‚ÙÙ€Ù€ÙˆÙ„Ù ÙÙÙ€Ù€ÙŠ Ù…ÙÙ€Ø·Ù’Ù€Ù„ÙØ¹ÙÙ‡ÙØ§ ØµÙÙ€Ù€ÙˆÙ’ØªÙ ØµÙÙ€ÙÙŠØ±Ù Ø§Ù„Ù€Ø¨ÙÙ„Ù’Ø¨ÙÙ„Ù\n"""
    if "ØµÙˆØª ØµÙÙŠØ± Ø§Ù„Ø¨Ù„Ø¨Ù„" in original_question or "Ù…Ø§ Ù‡ÙŠ Ù‚ØµÙŠØ¯Ø© ØµÙˆØª ØµÙÙŠØ± Ø§Ù„Ø¨Ù„Ø¨Ù„" in original_question and lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        return ssb
    elif  "ØµÙˆØª ØµÙÙŠØ± Ø§Ù„Ø¨Ù„Ø¨Ù„" in original_question or "Ù…Ø§ Ù‡ÙŠ Ù‚ØµÙŠØ¯Ø© ØµÙˆØª ØµÙÙŠØ± Ø§Ù„Ø¨Ù„Ø¨Ù„" and lang == "English":
        return translate_to_english(ssb)
    else:
    # Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø¹Ø§Ù…
        prompt = f"""
You are an expert assistant. The user asked a question.

Question: {question}

The question belongs to these categories:
- Main category: {cat1}
- Subcategory: {cat2}

Answer clearly and informatively.
""".strip()

    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„
        payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False
        }

        try:
            response = requests.post(OLLAMA_URL, json=payload, timeout=200)
            if response.status_code == 200:
                return response.json().get("response", "No response received.")
            else:
                return f"âŒ Error {response.status_code}: {response.text}"
        except requests.exceptions.ConnectionError:
            return "âŒ Ollama server not reachable. Make sure it's running."
        except Exception as e:
            return f"âŒ Exception: {str(e)}"

# ======= ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© =======

def translate_to_arabic(text):
    return GoogleTranslator(source='auto', target='ar').translate(text)

def classify_cat1(question):
    inputs = tokenizer_cat(question, return_tensors="pt", truncation=True, padding=True)
    outputs = model_cat(**inputs)
    pred = torch.argmax(outputs.logits).item()
    return label_map1.get(pred, "UNKNOWN"), pred

def classify_cat2(question):
    inputs = tokenizer_cat0(question, return_tensors="pt", truncation=True, padding=True)
    outputs = model_cat0(**inputs)
    pred = torch.argmax(outputs.logits).item()
    return label_map2.get(pred, "UNKNOWN"), pred

# ======= Ù†ØµÙˆØµ Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù„ØºØ§Øª =======
def get_text(key, lang):
    texts = {
        "title": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ğŸš€ Ù…Ø³Ø§Ø¹Ø¯ AI Ù…Ø­Ø³Ù†",
            "English": "ğŸš€ Enhanced AI assistant"
        },
        "subtitle": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ùƒ ÙˆØ§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ø¬Ø§Ø¨Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ!",
            "English": "Enter your question and get enhanced AI answer!"
        },
        "chat_title": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ğŸ’¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
            "English": "ğŸ’¬ Chat"
        },
        "input_label": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ğŸ“ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§",
            "English": "ğŸ“ Write your question here"
        },
        "ask_button": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ğŸ’¥ Ø§Ø³Ø£Ù„ Ø§Ù„Ø¢Ù†",
            "English": "ğŸ’¥ Ask Now"
        },
        "reset_button": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¹ÙŠÙŠÙ†",
            "English": "ğŸ”„ Reset"
        },
        "spinner_classify": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ğŸ” Ø¬Ø§Ø± Ø§Ù„ØªØµÙ†ÙŠÙ...",
            "English": "ğŸ” Classifying..."
        },
        "spinner_ollama": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "ğŸ¤– Ø¬Ø§Ø± Ø¬Ù„Ø¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Ollama...",
            "English": "ğŸ¤– Fetching answer from Ollama..."
        },
        "classification_label": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "**ğŸ“‚ Ø§Ù„ØªØµÙ†ÙŠÙ:**",
            "English": "**ğŸ“‚ Classification:**"
        },
        "main_category": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "- Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
            "English": "- Main category"
        },
        "sub_category": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "- Ø§Ù„ÙØ¦Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ©",
            "English": "- Subcategory"
        },
        "elapsed_time": {
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "â±ï¸ Ø§Ù„ÙˆÙ‚Øª",
            "English": "â±ï¸ Time"
        },
    }
    return texts.get(key, {}).get(lang, key)

# ======= ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© =======

st.set_page_config(page_title="AI Question Classifier", layout="wide")

lang_choice = st.radio("Ø§Ø®ØªØ± Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¶ / Choose display language:", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"], index=0, horizontal=True)
direction = "rtl" if lang_choice == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "ltr"

st.markdown(f"<h1 style='text-align: center; color: #ff4b5c;'>{get_text('title', lang_choice)}</h1>", unsafe_allow_html=True)
st.markdown(f"<p style='text-align: center; color: gray;'>{get_text('subtitle', lang_choice)}</p>", unsafe_allow_html=True)

if "messages" not in st.session_state:
    st.session_state.messages = []

st.markdown(f"<div style='direction: {direction}; text-align: {'right' if direction=='rtl' else 'left'};'>{get_text('chat_title', lang_choice)}</div>", unsafe_allow_html=True)

for msg in st.session_state.messages:
    st.markdown(
        f"""
        <div style='direction:{direction}; text-align:center;
        background:{"#ff4b5c" if msg["role"]=="user" else "#293C50"};
        color:white; padding:10px; border-radius:12px;
        margin:10px auto; max-width:70%;'>
        {msg['text']}
        </div>
        """, unsafe_allow_html=True
    )

with st.form("chat_form"):
    st.markdown('<div id="form-wrapper">', unsafe_allow_html=True)
    user_input = st.text_area(get_text("input_label", lang_choice), height=80)

    col1, col_spacer, col2 = st.columns([3, 1, 3])

    with col1:
        reset = st.form_submit_button(get_text("reset_button", lang_choice))
    with col2:
        send = st.form_submit_button(get_text("ask_button", lang_choice), type="primary")
    st.markdown('</div>', unsafe_allow_html=True)

st.markdown("""
<script>
document.addEventListener('keydown', function(event) {
    if (event.ctrlKey && event.key === 'Enter') {
        const form = document.querySelector('#form-wrapper')?.closest('form');
        if (form) {
            form.requestSubmit();
        }
    }
});

const buttons = document.querySelectorAll("div.stButton > button");
buttons.forEach(btn => {
    btn.style.width = "100%";
    btn.style.padding = "12px 0";
    btn.style.fontSize = "18px";
    btn.style.borderRadius = "8px";
});
</script>
""", unsafe_allow_html=True)


if "pending_question" in st.session_state:
    question = st.session_state.pending_question
    del st.session_state.pending_question  # Ù†Ø­Ø°ÙÙ‡Ø§ Ø¹Ø´Ø§Ù† Ù…Ø§ ØªØ¹ÙŠØ¯ Ù†ÙØ³Ù‡Ø§

    # ØªØ±Ø¬Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ø°Ø§ Ù„Ø§Ø²Ù…
    original_question = question
    if lang_choice == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" and not langdetect.detect(question) == 'en':
        question = translate_to_english(question)

    with st.spinner(get_text("spinner_classify", lang_choice)):
        cat1, cat1_idx = classify_cat1(question)
        cat2, cat2_idx = classify_cat2(question)
        if lang_choice == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            cat1 = label_map1_ar.get(cat1_idx, cat1)
            cat2 = label_map2_ar.get(cat2_idx, cat2)

    with st.spinner(get_text("spinner_ollama", lang_choice)):
        start_time = time.time()
        answer = query_ollama(question, cat1, cat2, original_question, lang_choice)
        if lang_choice == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            answer = translate_to_arabic(answer)
        elapsed = round(time.time() - start_time, 2)

    full_response = f"{answer}\n\n{get_text('classification_label', lang_choice)}\n{get_text('main_category', lang_choice)}: {cat1}\n{get_text('sub_category', lang_choice)}: {cat2}\n{get_text('elapsed_time', lang_choice)}: {elapsed} Ø«Ø§Ù†ÙŠØ©"

    st.session_state.messages.append({"role": "bot", "text": full_response})
    st.rerun()

if send and user_input.strip() != "":
    original_question = user_input.strip()
    question = original_question
    # Ø£Ø¶Ù Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙˆØ±Ù‹Ø§
    st.session_state.messages.append({"role": "user", "text": original_question})
    # Ù†Ø­ÙØ¸ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙÙŠ state Ø¹Ø´Ø§Ù† Ù†Ø³ØªØ®Ø¯Ù…Ù‡ Ø¨Ø¹Ø¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„
    st.session_state.pending_question = original_question
    st.rerun()

    # ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¥Ø°Ø§ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø®ØªØ§Ø±Ø©
    if lang_choice == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" and not langdetect.detect(question) == 'en':
        question = translate_to_english(question)

    with st.spinner(get_text("spinner_classify", lang_choice)):
        cat1, cat1_idx = classify_cat1(question)
        cat2, cat2_idx = classify_cat2(question)

        # ØªØ±Ø¬Ù…Ø© Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¥Ø°Ø§ Ù…Ø®ØªØ§Ø±Ø©
        if lang_choice == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            cat1 = label_map1_ar.get(cat1_idx, cat1)
            cat2 = label_map2_ar.get(cat2_idx, cat2)

    with st.spinner(get_text("spinner_ollama", lang_choice)):
        start_time = time.time()
        answer = query_ollama(question, cat1, cat2)
        # ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¬ÙˆØ§Ø¨ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¥Ø°Ø§ Ø§Ù„Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ©
        if lang_choice == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            answer = translate_to_arabic(answer)
        elapsed = round(time.time() - start_time, 2)
    second = "second" if lang_choice == "English" else "Ø«Ø§Ù†ÙŠØ©"
    full_response = f"{answer}\n\n{get_text('classification_label', lang_choice)}\n{get_text('main_category', lang_choice)}: {cat1}\n{get_text('sub_category', lang_choice)}:\n {cat2}\n{get_text('elapsed_time', lang_choice)}: {elapsed}" + second

    st.session_state.messages.append({"role": "user", "text": original_question})
    st.session_state.messages.append({"role": "bot", "text": full_response})
    st.rerun()

if reset:
    st.session_state.messages.clear()
    st.rerun()
